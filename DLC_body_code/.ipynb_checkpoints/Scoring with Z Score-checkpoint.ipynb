{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy import stats\n",
    "import glob, os\n",
    "import datetime as dt\n",
    "from scipy.signal import find_peaks, peak_prominences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnesting(df, explode):\n",
    "    idx = df.index.repeat(df[explode[0]].str.len())\n",
    "    df1 = pd.concat([\n",
    "        pd.DataFrame({x: np.concatenate(df[x].values)}) for x in explode], axis=1)\n",
    "    df1.index = idx\n",
    "\n",
    "    return df1.join(df.drop(explode, 1), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"MC30\",\"MC70\"]\n",
    "for subject in subjects:\n",
    "    folder = \"/home/ml/Documents/Not_TADSS_Videos/\"+subject+\"/cut/dlc_output_16-810\"\n",
    "    folder2 = \"/home/ml/Documents/z_scoring/\"+subject+\"/\"\n",
    "    #empty list of files\n",
    "    files = []\n",
    "    os.chdir(folder)\n",
    "    injured = \"Front Right\"\n",
    "    for file in glob.glob(\"*.h5\"):\n",
    "        files.append(file)\n",
    "        #print(file)\n",
    "    peaks = []\n",
    "    peakcols = [\"subject\",\"date\",\"run\",\"peak_fr_x\",\"peak_fr_y\",\"likelihood_fr\",\"peak_fl_x\",\"peak_fl_y\",\"likelihood_fl\",\"peak_br_x\",\"peak_br_y\",\"likelihood_br\",\"peak_bl_x\",\"peak_bl_y\",\"likelihood_bl\",\"z-score_fr\",\"z-score_fl\",\"z-score_br\",\"z-score_bl\"]\n",
    "    xdist = -20\n",
    "    likes_fr = []\n",
    "    likes_fl = []\n",
    "    likes_bl = []\n",
    "    likes_br = []\n",
    "    \n",
    "    for data in files:\n",
    "        subject = data.split(\"_\")[0]\n",
    "        date = data.split(\"_\")[1]\n",
    "        run = data.split(\"_\")[2]\n",
    "        df = pd.read_hdf(data)\n",
    "        pred = 0.1\n",
    "\n",
    "        #split by limb\n",
    "        #front = fingers, back = toes\n",
    "        #frontright\n",
    "        \n",
    "        df_fr = df['DLC_resnet101_LadderWalkFeb13shuffle1_1030000']['right fingers']\n",
    "        \n",
    "        #frontleft\n",
    "        \n",
    "        df_fl = df['DLC_resnet101_LadderWalkFeb13shuffle1_1030000']['left fingers']\n",
    "        \n",
    "        #backright\n",
    "        \n",
    "        df_br = df['DLC_resnet101_LadderWalkFeb13shuffle1_1030000']['right toes']\n",
    "        #back left\n",
    "        \n",
    "        df_bl = df['DLC_resnet101_LadderWalkFeb13shuffle1_1030000']['left toes']\n",
    "        \n",
    "        \n",
    "        likes_fr.append(df_fr[\"likelihood\"].values)\n",
    "        likes_fl.append(df_fl[\"likelihood\"].values)\n",
    "        likes_br.append(df_br[\"likelihood\"].values)\n",
    "        likes_bl.append(df_bl[\"likelihood\"].values)\n",
    "        \n",
    "        df_fr = df_fr.loc[df_fr['likelihood']>pred]\n",
    "        df_fr = df_fr.reset_index()\n",
    "        df_fr.name = \"Front Right\"\n",
    "        \n",
    "        df_fl = df_fl.loc[df_fl['likelihood']>pred]\n",
    "        df_fl = df_fl.reset_index()\n",
    "        df_fl.name = \"Front Left\"\n",
    "        \n",
    "        df_br = df_br.loc[df_br['likelihood']>pred]\n",
    "        df_br = df_br.reset_index()\n",
    "        df_br.name = \"Back Right\"\n",
    "        \n",
    "        df_bl = df_bl.loc[df_bl['likelihood']>pred]\n",
    "        df_bl = df_bl.reset_index()\n",
    "        df_bl.name = \"Back Left\"\n",
    "        \n",
    "        \n",
    "        like_fr = df_fr[\"likelihood\"]\n",
    "        like_fl = df_fl[\"likelihood\"]\n",
    "        like_br = df_br[\"likelihood\"]\n",
    "        like_bl = df_bl[\"likelihood\"]\n",
    "        \n",
    "        \n",
    "        x_fr = df_fr[\"x\"]\n",
    "        y_fr = df_fr[\"y\"]\n",
    "\n",
    "        x_fl = df_fl[\"x\"]\n",
    "        y_fl = df_fl[\"y\"]\n",
    "\n",
    "        x_br = df_br[\"x\"]\n",
    "        y_br = df_br[\"y\"]\n",
    "\n",
    "        x_bl = df_bl[\"x\"]\n",
    "        y_bl = df_bl[\"y\"]\n",
    "        \n",
    "        promperc = 40\n",
    "        \n",
    "        #find prominences of local minima\n",
    "        peaks_fr = find_peaks(y_fr,prominence=0)\n",
    "        proms_fr = peaks_fr[1]['prominences']\n",
    "        if len(proms_fr)>=1:\n",
    "            prom_fr = np.percentile(proms_fr,promperc).min()\n",
    "        else:\n",
    "            prom_fr = 0\n",
    "\n",
    "        \n",
    "        peaks_fl = find_peaks(y_fl,prominence=0)\n",
    "        proms_fl = peaks_fl[1]['prominences']\n",
    "        if len(proms_fl)>=1:\n",
    "            prom_fl = np.percentile(proms_fl,promperc).min()\n",
    "        else:\n",
    "            prom_fl = 0\n",
    "        \n",
    "        \n",
    "        peaks_br = find_peaks(y_br,prominence=0)\n",
    "        proms_br = peaks_br[1]['prominences']\n",
    "        if len(proms_br)>=1:\n",
    "            prom_br = np.percentile(proms_br,promperc).min()\n",
    "        else:\n",
    "            prom_br = 0\n",
    "        \n",
    "        \n",
    "        peaks_bl = find_peaks(y_bl,prominence=0)\n",
    "        proms_bl = peaks_bl[1]['prominences']\n",
    "        \n",
    "        if len(proms_bl)>=1:\n",
    "            prom_bl = np.percentile(proms_bl,promperc).min()\n",
    "        else:\n",
    "            prom_bl = 0\n",
    "        \n",
    "        \n",
    "        dh = 25\n",
    "\n",
    "        \n",
    "        med_fr = np.median(y_fr)\n",
    "        peaks_fr= find_peaks(y_fr, height = med_fr-dh, prominence=prom_fr)\n",
    "\n",
    "        med_fl = np.median(y_fl)\n",
    "        peaks_fl= find_peaks(y_fl, height = med_fl-dh, prominence=prom_fl)\n",
    "\n",
    "        med_br = np.median(y_br)\n",
    "        peaks_br= find_peaks(y_br, height = med_br-dh, prominence=prom_br)\n",
    "\n",
    "        med_bl = np.median(y_bl)\n",
    "        peaks_bl= find_peaks(y_bl, height = med_bl-dh, prominence=prom_bl)\n",
    "        zsc_fr = (np.abs(stats.zscore(y_fr[peaks_fr[0]])))\n",
    "        zsc_fl = (np.abs(stats.zscore(y_fl[peaks_fl[0]])))\n",
    "        zsc_br = (np.abs(stats.zscore(y_br[peaks_br[0]])))\n",
    "        zsc_bl = (np.abs(stats.zscore(y_bl[peaks_bl[0]])))\n",
    "        \n",
    "        peaks.append([subject,date,run,x_fr[peaks_fr[0]],y_fr[peaks_fr[0]],like_fr[peaks_fr[0]],x_fl[peaks_fl[0]],y_fl[peaks_fl[0]],like_fl[peaks_fl[0]],x_br[peaks_br[0]],y_br[peaks_br[0]],like_br[peaks_br[0]],x_bl[peaks_bl[0]],y_bl[peaks_bl[0]],like_bl[peaks_bl[0]],zsc_fr,zsc_fl,zsc_br,zsc_bl])\n",
    "        \n",
    "        xdist_df = pd.DataFrame([[subject,date,run,x_fr[peaks_fr[0]],y_fr[peaks_fr[0]],like_fr[peaks_fr[0]],x_fl[peaks_fl[0]],y_fl[peaks_fl[0]],like_fl[peaks_fl[0]],x_br[peaks_br[0]],y_br[peaks_br[0]],like_br[peaks_br[0]],x_bl[peaks_bl[0]],y_bl[peaks_bl[0]],like_bl[peaks_bl[0]],zsc_fr,zsc_fl,zsc_br,zsc_bl]],columns=peakcols)\n",
    "        xdist_df[\"daterun\"] = xdist_df[\"date\"].map(str) +\" \"+ xdist_df[\"run\"]\n",
    "        frontr_df = unnesting(xdist_df[['subject','daterun','peak_fr_x','peak_fr_y']],['peak_fr_x','peak_fr_y'])\n",
    "        frontl_df = unnesting(xdist_df[['subject','daterun','peak_fl_x','peak_fl_y']],['peak_fl_x','peak_fl_y'])\n",
    "        backr_df = unnesting(xdist_df[['subject','daterun','peak_br_x','peak_br_y']],['peak_br_x','peak_br_y'])\n",
    "        backl_df = unnesting(xdist_df[['subject','daterun','peak_bl_x','peak_bl_y']],['peak_bl_x','peak_bl_y'])\n",
    "        \n",
    "        \n",
    "        frontr_df = frontr_df.sort_values([\"peak_fr_x\"],ascending=False)\n",
    "        frontr_df[\"diff\"]=frontr_df.groupby([\"subject\",\"daterun\"])[\"peak_fr_x\"].diff()\n",
    "        frontr_df[\"keep\"] = \"Y\"\n",
    "        frontr_df.loc[(frontr_df[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "        frontr_df = frontr_df.loc[frontr_df[\"keep\"]==\"Y\"]\n",
    "        \n",
    "        frontl_df = frontl_df.sort_values([\"peak_fl_x\"],ascending=False)\n",
    "        frontl_df[\"diff\"]=frontl_df.groupby([\"subject\",\"daterun\"])[\"peak_fl_x\"].diff()\n",
    "        frontl_df[\"keep\"] = \"Y\"\n",
    "        frontl_df.loc[(frontl_df[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "        frontl_df = frontl_df.loc[frontl_df[\"keep\"]==\"Y\"]\n",
    "        \n",
    "        backr_df = backr_df.sort_values([\"peak_br_x\"],ascending=False)\n",
    "        backr_df[\"diff\"]=backr_df.groupby([\"subject\",\"daterun\"])[\"peak_br_x\"].diff()\n",
    "        backr_df[\"keep\"] = \"Y\"\n",
    "        backr_df.loc[(backr_df[\"diff\"]>xdist),\"keep\"] = \"N\"\n",
    "        backr_df = backr_df.loc[backr_df[\"keep\"]==\"Y\"]\n",
    "        \n",
    "        backl_df = backl_df.sort_values([\"peak_bl_x\"],ascending=False)\n",
    "        backl_df[\"diff\"]=backl_df.groupby([\"subject\",\"daterun\"])[\"peak_bl_x\"].diff()\n",
    "        backl_df[\"keep\"] = \"Y\"\n",
    "        backl_df.loc[(backl_df[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "        backl_df = backl_df.loc[backl_df[\"keep\"]==\"Y\"]\n",
    "        \n",
    "    df2 = pd.DataFrame(peaks,columns=peakcols)\n",
    "    df2[\"daterun\"] = df2[\"date\"].map(str) +\" \"+ df2[\"run\"]\n",
    "    \n",
    "    fr = unnesting(df2[[\"subject\",\"daterun\",\"peak_fr_x\",\"peak_fr_y\",\"likelihood_fr\",\"z-score_fr\"]],['peak_fr_x','peak_fr_y',\"likelihood_fr\",\"z-score_fr\"])\n",
    "    fr = fr[[\"subject\",\"daterun\",\"peak_fr_x\",\"peak_fr_y\",\"likelihood_fr\",\"z-score_fr\"]]\n",
    "    fr = fr.rename(columns={\"daterun\":\"daterun\",\"peak_fr_x\":\"x\",\"peak_fr_y\":\"y\",\"likelihood_fr\":\"likelihood\",\"z-score_fr\":\"z-score\"})\n",
    "    fr[\"limb\"] = \"Front Right\"\n",
    "    fr = fr.reset_index()\n",
    "    fr = fr.drop(\"index\",axis=1)\n",
    "    \n",
    "    peak_df_fr = fr\n",
    "    peak_df_fr = peak_df_fr.sort_values([\"daterun\",\"x\"],ascending=False)\n",
    "    peak_df_fr[\"diff\"]=peak_df_fr.groupby([\"subject\",\"daterun\",\"limb\"])[\"x\"].diff()\n",
    "    peak_df_fr[\"keep\"] = \"Y\"\n",
    "    peak_df_fr.loc[(peak_df_fr[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "    peak_df_fr = peak_df_fr.loc[peak_df_fr[\"keep\"]==\"Y\"]\n",
    "\n",
    "    fl = unnesting(df2[[\"subject\",'daterun','peak_fl_x','peak_fl_y',\"likelihood_fl\",\"z-score_fl\"]],['peak_fl_x','peak_fl_y',\"likelihood_fl\",\"z-score_fl\"])\n",
    "    fl = fl[[\"subject\",'daterun','peak_fl_x','peak_fl_y',\"likelihood_fl\",\"z-score_fl\"]]\n",
    "    fl = fl.rename(columns={\"daterun\":\"daterun\",\"peak_fl_x\":\"x\",\"peak_fl_y\":\"y\",\"likelihood_fl\":\"likelihood\",\"z-score_fl\":\"z-score\"})\n",
    "    fl[\"limb\"] = \"Front Left\"\n",
    "    fl = fl.reset_index()\n",
    "    fl = fl.drop(\"index\",axis=1)\n",
    "    \n",
    "    peak_df_fl = fl\n",
    "    peak_df_fl = peak_df_fl.sort_values([\"daterun\",\"x\"],ascending=False)\n",
    "    peak_df_fl[\"diff\"]=peak_df_fl.groupby([\"subject\",\"daterun\",\"limb\"])[\"x\"].diff()\n",
    "    peak_df_fl[\"keep\"] = \"Y\"\n",
    "    peak_df_fl.loc[(peak_df_fl[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "    peak_df_fl = peak_df_fl.loc[peak_df_fl[\"keep\"]==\"Y\"]\n",
    "\n",
    "    br = unnesting(df2[[\"subject\",'daterun','peak_br_x','peak_br_y',\"likelihood_br\",\"z-score_br\"]],['peak_br_x','peak_br_y',\"likelihood_br\",\"z-score_br\"])\n",
    "    br = br[[\"subject\",'daterun','peak_br_x','peak_br_y',\"likelihood_br\",\"z-score_br\"]]\n",
    "    br = br.rename(columns={\"daterun\":\"daterun\",\"peak_br_x\":\"x\",\"peak_br_y\":\"y\",\"likelihood_br\":\"likelihood\",\"z-score_br\":\"z-score\"})\n",
    "    br[\"limb\"] = \"Back Right\"\n",
    "    br = br.reset_index()\n",
    "    br = br.drop(\"index\",axis=1)\n",
    "    \n",
    "    peak_df_br = br\n",
    "    peak_df_br = peak_df_br.sort_values([\"daterun\",\"x\"],ascending=False)\n",
    "    peak_df_br[\"diff\"]=peak_df_br.groupby([\"subject\",\"daterun\",\"limb\"])[\"x\"].diff()\n",
    "    peak_df_br[\"keep\"] = \"Y\"\n",
    "    peak_df_br.loc[(peak_df_br[\"diff\"])>xdist,\"keep\"] = \"N\"\n",
    "    peak_df_br = peak_df_br.loc[peak_df_br[\"keep\"]==\"Y\"]\n",
    "\n",
    "    bl = unnesting(df2[[\"subject\",'daterun','peak_bl_x','peak_bl_y',\"likelihood_bl\",\"z-score_bl\"]],['peak_bl_x','peak_bl_y',\"likelihood_bl\",\"z-score_bl\"])\n",
    "    bl = bl[[\"subject\",'daterun','peak_bl_x','peak_bl_y',\"likelihood_bl\",\"z-score_bl\"]]\n",
    "    bl = bl.rename(columns={\"daterun\":\"daterun\",\"peak_bl_x\":\"x\",\"peak_bl_y\":\"y\",\"likelihood_bl\":\"likelihood\",\"z-score_bl\":\"z-score\"})\n",
    "    bl[\"limb\"] = \"Back Left\"\n",
    "    bl = bl.reset_index()\n",
    "    bl = bl.drop(\"index\",axis=1)\n",
    "    \n",
    "    peak_df_bl = bl\n",
    "    peak_df_bl = peak_df_bl.sort_values([\"daterun\",\"x\"],ascending=False)\n",
    "    peak_df_bl[\"diff\"]=peak_df_bl.groupby([\"subject\",\"daterun\",\"limb\"])[\"x\"].diff()\n",
    "    peak_df_bl[\"keep\"] = \"Y\"\n",
    "    peak_df_bl.loc[(peak_df_bl[\"diff\"]>xdist),\"keep\"] = \"N\"\n",
    "    peak_df_bl = peak_df_bl.loc[peak_df_bl[\"keep\"]==\"Y\"]\n",
    "    \n",
    "    concatlist = [peak_df_fr,peak_df_fl,peak_df_br,peak_df_bl]\n",
    "    newdf = pd.concat(concatlist)\n",
    "    #newdf.to_csv(folder2+\"/\"+subject+\"_peaks.csv\")\n",
    "    \n",
    "    zreq = 2\n",
    "    zreq_injured = 2\n",
    "    #was 0.6\n",
    "    \n",
    "    zdf = newdf.drop([\"z-score\"],axis = 1)\n",
    "    #recalculate z-score of peaks using all the limbs\n",
    "    zdf2 = zdf.groupby(['subject','daterun']).y.transform(lambda x : np.abs(stats.zscore(x)))\n",
    "    zdf['z-score'] = zdf2\n",
    "                                                                   \n",
    "    hitdf = zdf.loc[ (zdf['z-score']<=zreq) | ((zdf['z-score']<=zreq_injured) & (zdf['limb']==injured))].groupby(['subject','daterun','limb'])['z-score'].count()\n",
    "    #hitdf = hitdf.drop(['y','likelihood','limb','z-score'],axis=1)\n",
    "    #hitdf = hitdf.rename(columns={'x':'dlc_hits'})\n",
    "    slipdf = zdf.loc[ (zdf['z-score']>zreq) | ((zdf['z-score']>zreq_injured) & (zdf['limb']==injured))].groupby(['subject','daterun','limb'])['z-score'].count()\n",
    "    #slipdf = slipdf.drop(['y','likelihood','limb','z-score'],axis=1)\n",
    "    #slipdf = slipdf.rename(columns={'x':'dlc_miss'})\n",
    "    #stepdf = zdf.groupby(['subject','daterun','limb'])['z-score'].count()\n",
    "    #stepdf = stepdf.drop(['y','likelihood','limb','z-score'],axis=1)\n",
    "    #stepdf = stepdf.rename(columns={'x':'dlc_steps'})\n",
    "    \n",
    "    scoredf = pd.DataFrame()\n",
    "    scoredf['dlc_hits'] = hitdf\n",
    "    scoredf['dlc_slips'] = slipdf\n",
    "    scoredf = scoredf.fillna(0)\n",
    "    scoredf['dlc_steps'] = scoredf['dlc_hits'].add(scoredf['dlc_slips'])\n",
    "    scoredf = scoredf.reset_index()\n",
    "    scoredf[['date',\"run\"]] = scoredf.daterun.str.split(expand=True)\n",
    "    scoredf = scoredf.drop(\"daterun\",axis=1)\n",
    "    scoredf = scoredf[[\"subject\",\"date\",\"run\",\"limb\",\"dlc_hits\",\"dlc_slips\",\"dlc_steps\"]]\n",
    "    scoredf['date'] = pd.to_datetime(scoredf[\"date\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
